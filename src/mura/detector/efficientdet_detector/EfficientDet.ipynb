{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EfficientDet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "C4RpART-IBSz"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZa49OYhOp2k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d861bf-4a8b-45de-f37c-061f3e33d394"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wapJXYOmd9CN"
      },
      "source": [
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jekVUiBUeXMC"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/EfficientDet2/')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6lyNUEC5LIE"
      },
      "source": [
        "#1. Zylo117"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XKXMlbZPf4d"
      },
      "source": [
        "# Install requirements\n",
        "\n",
        "!pip install pycocotools numpy opencv-python tqdm tensorboard tensorboardX pyyaml webcolors\n",
        "# !pip install torch==1.4.0\n",
        "# !pip install torchvision==0.5.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl7htJc8dkbG"
      },
      "source": [
        "# Download pretrain weights\n",
        "\n",
        "!wget https://github.com/zylo117/Yet-Another-Efficient-Pytorch/releases/download/1.0/efficientdet-d0.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMEqg7D0eaw6"
      },
      "source": [
        "Create .yml file in projects directory\n",
        " \n",
        "```\n",
        "project_name: EfficientDet2\n",
        "train_set: train\n",
        "val_set: val\n",
        "num_gpus: 1  # 0 means using cpu, 1-N means using gpus \n",
        "\n",
        "# mean and std in RGB order, actually this part should remain unchanged as long as your dataset is similar to coco.\n",
        "mean: [0.485, 0.456, 0.406]\n",
        "std: [0.229, 0.224, 0.225]\n",
        "\n",
        "# this is coco anchors, change it if necessary\n",
        "anchors_scales: '[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]'\n",
        "anchors_ratios: '[(1.0, 1.0), (1.4, 0.7), (0.7, 1.4)]'\n",
        "\n",
        "# objects from all labels from your dataset with the order from your annotations.\n",
        "# its index must match your dataset's category_id.\n",
        "# category_id is one_indexed,\n",
        "# for example, index of 'car' here is 2, while category_id of is 3\n",
        "obj_list: ['fracture']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OmcmnxXM-hl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0fbb9ef-7fa8-4b38-8669-d6181207fcf6"
      },
      "source": [
        "# Train in xray image\n",
        "\n",
        "!python train.py -c 1 -p EfficientDet2 --batch_size 8 --lr 1e-5 --num_epochs 200 --load_weights last"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "using weights logs//EfficientDet2/efficientdet-d1_118_4522.pth\n",
            "[Info] loaded weights: efficientdet-d1_118_4522.pth, resuming checkpoint from step: 4522\n",
            "Step: 4559. Epoch: 119/200. Iteration: 38/38. Cls loss: 0.02397. Reg loss: 0.13585. Total loss: 0.15982: 100% 38/38 [02:44<00:00,  4.34s/it]\n",
            "Val. Epoch: 119/200. Classification loss: 0.45522. Regression loss: 2.54749. Total loss: 3.00271\n",
            "Step: 4597. Epoch: 120/200. Iteration: 38/38. Cls loss: 0.02064. Reg loss: 0.08261. Total loss: 0.10325: 100% 38/38 [02:45<00:00,  4.35s/it]\n",
            "Val. Epoch: 120/200. Classification loss: 0.45774. Regression loss: 2.54636. Total loss: 3.00410\n",
            "Step: 4635. Epoch: 121/200. Iteration: 38/38. Cls loss: 0.03800. Reg loss: 0.17674. Total loss: 0.21474: 100% 38/38 [02:45<00:00,  4.36s/it]\n",
            "Val. Epoch: 121/200. Classification loss: 0.46419. Regression loss: 2.56156. Total loss: 3.02575\n",
            "Step: 4673. Epoch: 122/200. Iteration: 38/38. Cls loss: 0.02208. Reg loss: 0.07105. Total loss: 0.09313: 100% 38/38 [02:45<00:00,  4.36s/it]\n",
            "Val. Epoch: 122/200. Classification loss: 0.46249. Regression loss: 2.54359. Total loss: 3.00608\n",
            "Step: 4711. Epoch: 123/200. Iteration: 38/38. Cls loss: 0.02583. Reg loss: 0.10149. Total loss: 0.12732: 100% 38/38 [02:45<00:00,  4.35s/it]\n",
            "Val. Epoch: 123/200. Classification loss: 0.46564. Regression loss: 2.56487. Total loss: 3.03050\n",
            "Step: 4749. Epoch: 124/200. Iteration: 38/38. Cls loss: 0.05378. Reg loss: 0.24882. Total loss: 0.30260: 100% 38/38 [02:45<00:00,  4.36s/it]\n",
            "Epoch     6: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Val. Epoch: 124/200. Classification loss: 0.46594. Regression loss: 2.55656. Total loss: 3.02250\n",
            "Step: 4787. Epoch: 125/200. Iteration: 38/38. Cls loss: 0.02321. Reg loss: 0.11780. Total loss: 0.14101: 100% 38/38 [02:45<00:00,  4.36s/it]\n",
            "Val. Epoch: 125/200. Classification loss: 0.46504. Regression loss: 2.55222. Total loss: 3.01726\n",
            "Step: 4825. Epoch: 126/200. Iteration: 38/38. Cls loss: 0.02123. Reg loss: 0.08671. Total loss: 0.10794: 100% 38/38 [02:45<00:00,  4.36s/it]\n",
            "Val. Epoch: 126/200. Classification loss: 0.46581. Regression loss: 2.55380. Total loss: 3.01960\n",
            "Step: 4863. Epoch: 127/200. Iteration: 38/38. Cls loss: 0.02308. Reg loss: 0.09026. Total loss: 0.11334: 100% 38/38 [02:45<00:00,  4.36s/it]\n",
            "Val. Epoch: 127/200. Classification loss: 0.46508. Regression loss: 2.55205. Total loss: 3.01713\n",
            "Step: 4901. Epoch: 128/200. Iteration: 38/38. Cls loss: 0.04411. Reg loss: 0.15435. Total loss: 0.19846: 100% 38/38 [02:45<00:00,  4.35s/it]\n",
            "Val. Epoch: 128/200. Classification loss: 0.46554. Regression loss: 2.55232. Total loss: 3.01787\n",
            "Step: 4939. Epoch: 129/200. Iteration: 38/38. Cls loss: 0.02958. Reg loss: 0.11965. Total loss: 0.14924: 100% 38/38 [02:45<00:00,  4.35s/it]\n",
            "Val. Epoch: 129/200. Classification loss: 0.46649. Regression loss: 2.55786. Total loss: 3.02435\n",
            "Step: 4940. Epoch: 130/200. Iteration: 1/38. Cls loss: 0.03133. Reg loss: 0.12138. Total loss: 0.15271:   3% 1/38 [00:08<05:13,  8.47s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ckj189LTxIK",
        "outputId": "80f2a83d-7186-485b-cbe6-fb22cba92db2"
      },
      "source": [
        "!python coco_eval.py -p EfficientDet2 -c 1 -w /content/drive/MyDrive/EfficientDet2/logs/EfficientDet2/efficientdet-d1_118_4522.pth"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running coco-style evaluation on project EfficientDet2, weights /content/drive/MyDrive/EfficientDet2/logs/EfficientDet2/efficientdet-d1_118_4522.pth...\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "100% 100/100 [00:05<00:00, 17.32it/s]\n",
            "Loading and preparing results...\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "BBox\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.10s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.02s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.272\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.657\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.120\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.116\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.278\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.334\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.308\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.407\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.411\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.414\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53J6mhou65LP",
        "outputId": "34421ea2-8af7-4628-da9b-07808aa9064f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "backbone.py\t\t     efficientnet  res\n",
            "benchmark\t\t     LICENSE\t   test\n",
            "coco_eval.py\t\t     logs\t   train.py\n",
            "datasets\t\t     pretrain\t   tutorial\n",
            "efficientdet\t\t     projects\t   utils\n",
            "efficientdet_test.py\t     __pycache__   val2017_bbox_results.json\n",
            "efficientdet_test_videos.py  readme.md\t   val_bbox_results.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dPXHqrb5d5w",
        "outputId": "3b41fa87-279f-47b8-b57c-48844583bc2f"
      },
      "source": [
        "# Prediction\n",
        "import torch\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from backbone import EfficientDetBackbone\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import glob\n",
        "import random\n",
        "\n",
        "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
        "from utils.utils import preprocess, invert_affine, postprocess\n",
        "\n",
        "compound_coef = 1\n",
        "id = 0\n",
        "force_input_size = None  # set None to use default size\n",
        "\n",
        "for img_path in glob.glob('/content/drive/MyDrive/EfficientDet2/datasets/EfficientDet2/val/*.jpg'):\n",
        "  id += 1\n",
        "  threshold = 0.25\n",
        "  iou_threshold = 0.2\n",
        "\n",
        "  use_cuda = True\n",
        "  use_float16 = False\n",
        "  cudnn.fastest = True\n",
        "  cudnn.benchmark = True\n",
        "\n",
        "  obj_list = ['fracture']\n",
        "\n",
        "  # tf bilinear interpolation is different from any other's, just make do\n",
        "  input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]\n",
        "  input_size = input_sizes[compound_coef] if force_input_size is None else force_input_size\n",
        "  ori_imgs, framed_imgs, framed_metas = preprocess(img_path, max_size=input_size)\n",
        "\n",
        "  if use_cuda:\n",
        "      x = torch.stack([torch.from_numpy(fi).cuda() for fi in framed_imgs], 0)\n",
        "  else:\n",
        "      x = torch.stack([torch.from_numpy(fi) for fi in framed_imgs], 0)\n",
        "\n",
        "  x = x.to(torch.float32 if not use_float16 else torch.float16).permute(0, 3, 1, 2)\n",
        "\n",
        "  model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list),\n",
        "\n",
        "                               # replace this part with your project's anchor config\n",
        "                               ratios=[(0.7, 1.4), (1.0, 1.0), (1.5, 0.7)],\n",
        "                               scales=[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)])\n",
        "\n",
        "  model.load_state_dict(torch.load('/content/drive/MyDrive/EfficientDet2/logs/EfficientDet2/efficientdet-d1_118_4522.pth'))\n",
        "  model.requires_grad_(False)\n",
        "  model.eval()\n",
        "\n",
        "  if use_cuda:\n",
        "      model = model.cuda()\n",
        "  if use_float16:\n",
        "      model = model.half()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      features, regression, classification, anchors = model(x)\n",
        "\n",
        "      regressBoxes = BBoxTransform()\n",
        "      clipBoxes = ClipBoxes()\n",
        "\n",
        "      out = postprocess(x,\n",
        "                        anchors, regression, classification,\n",
        "                        regressBoxes, clipBoxes,\n",
        "                        threshold, iou_threshold)\n",
        "\n",
        "  out = invert_affine(framed_metas, out)\n",
        "  image = ori_imgs[0]\n",
        "  for i in range(len(ori_imgs)):\n",
        "      if len(out[i]['rois']) == 0:\n",
        "          continue\n",
        "      ori_imgs[i] = ori_imgs[i].copy()\n",
        "      for j in range(len(out[i]['rois'])):\n",
        "          (x1, y1, x2, y2) = out[i]['rois'][j].astype(np.int)\n",
        "          cv2.rectangle(ori_imgs[i], (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
        "          obj = obj_list[out[i]['class_ids'][j]]\n",
        "          score = float(out[i]['scores'][j])\n",
        "\n",
        "          image = cv2.putText(ori_imgs[i], '{}, {:.3f}'.format(obj, score),\n",
        "                      (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                      (255, 255, 0), 1)\n",
        "\n",
        "  cv2.imwrite(f'res/{id}.jpg', image)\n",
        "  print(f'image {id}: Saved!')\n",
        "    # plt.figure(figsize=(7, 7))\n",
        "    # plt.imshow(image)\n",
        "    # plt.savefig('res/1.jpg')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image 1: Saved!\n",
            "image 2: Saved!\n",
            "image 3: Saved!\n",
            "image 4: Saved!\n",
            "image 5: Saved!\n",
            "image 6: Saved!\n",
            "image 7: Saved!\n",
            "image 8: Saved!\n",
            "image 9: Saved!\n",
            "image 10: Saved!\n",
            "image 11: Saved!\n",
            "image 12: Saved!\n",
            "image 13: Saved!\n",
            "image 14: Saved!\n",
            "image 15: Saved!\n",
            "image 16: Saved!\n",
            "image 17: Saved!\n",
            "image 18: Saved!\n",
            "image 19: Saved!\n",
            "image 20: Saved!\n",
            "image 21: Saved!\n",
            "image 22: Saved!\n",
            "image 23: Saved!\n",
            "image 24: Saved!\n",
            "image 25: Saved!\n",
            "image 26: Saved!\n",
            "image 27: Saved!\n",
            "image 28: Saved!\n",
            "image 29: Saved!\n",
            "image 30: Saved!\n",
            "image 31: Saved!\n",
            "image 32: Saved!\n",
            "image 33: Saved!\n",
            "image 34: Saved!\n",
            "image 35: Saved!\n",
            "image 36: Saved!\n",
            "image 37: Saved!\n",
            "image 38: Saved!\n",
            "image 39: Saved!\n",
            "image 40: Saved!\n",
            "image 41: Saved!\n",
            "image 42: Saved!\n",
            "image 43: Saved!\n",
            "image 44: Saved!\n",
            "image 45: Saved!\n",
            "image 46: Saved!\n",
            "image 47: Saved!\n",
            "image 48: Saved!\n",
            "image 49: Saved!\n",
            "image 50: Saved!\n",
            "image 51: Saved!\n",
            "image 52: Saved!\n",
            "image 53: Saved!\n",
            "image 54: Saved!\n",
            "image 55: Saved!\n",
            "image 56: Saved!\n",
            "image 57: Saved!\n",
            "image 58: Saved!\n",
            "image 59: Saved!\n",
            "image 60: Saved!\n",
            "image 61: Saved!\n",
            "image 62: Saved!\n",
            "image 63: Saved!\n",
            "image 64: Saved!\n",
            "image 65: Saved!\n",
            "image 66: Saved!\n",
            "image 67: Saved!\n",
            "image 68: Saved!\n",
            "image 69: Saved!\n",
            "image 70: Saved!\n",
            "image 71: Saved!\n",
            "image 72: Saved!\n",
            "image 73: Saved!\n",
            "image 74: Saved!\n",
            "image 75: Saved!\n",
            "image 76: Saved!\n",
            "image 77: Saved!\n",
            "image 78: Saved!\n",
            "image 79: Saved!\n",
            "image 80: Saved!\n",
            "image 81: Saved!\n",
            "image 82: Saved!\n",
            "image 83: Saved!\n",
            "image 84: Saved!\n",
            "image 85: Saved!\n",
            "image 86: Saved!\n",
            "image 87: Saved!\n",
            "image 88: Saved!\n",
            "image 89: Saved!\n",
            "image 90: Saved!\n",
            "image 91: Saved!\n",
            "image 92: Saved!\n",
            "image 93: Saved!\n",
            "image 94: Saved!\n",
            "image 95: Saved!\n",
            "image 96: Saved!\n",
            "image 97: Saved!\n",
            "image 98: Saved!\n",
            "image 99: Saved!\n",
            "image 100: Saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZriquhI5Q2z"
      },
      "source": [
        "#2. Roboflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0isUWECteNH",
        "outputId": "9be84587-89f8-4a89-9f77-17ae167cdf94"
      },
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehzSNoWltxso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e890abf3-881c-4cac-ddbf-2418ab66308d"
      },
      "source": [
        "! git clone https://github.com/roboflow-ai/Monk_Object_Detection.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Monk_Object_Detection' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emPnzoSnt-YT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61858bb-ceed-44f1-89ce-46be732738f6"
      },
      "source": [
        "! cd Monk_Object_Detection/3_mxrcnn/installation && cat requirements_colab.txt | xargs -n 1 -L 1 pip install"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet-cu100 in /usr/local/lib/python3.7/dist-packages (1.8.0.post0)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu100) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu100) (1.19.5)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu100) (0.8.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (3.0.4)\n",
            "Requirement already satisfied: dicttoxml in /usr/local/lib/python3.7/dist-packages (1.7.4)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl053L0xu2Dq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86122cf3-2ed2-47cb-f6d3-1d19c51524a3"
      },
      "source": [
        "#fixed version of tqdm output for Colab\n",
        "!pip install --force https://github.com/chengs/tqdm/archive/colab.zip\n",
        "#IGNORE restart runtime warning, it is indeed installed\n",
        "#missing a few extra packages that we will need later! \n",
        "!pip install efficientnet_pytorch\n",
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/chengs/tqdm/archive/colab.zip\n",
            "  Using cached https://github.com/chengs/tqdm/archive/colab.zip\n",
            "Building wheels for collected packages: tqdm\n",
            "  Building wheel for tqdm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tqdm: filename=tqdm-4.28.1-py2.py3-none-any.whl size=47868 sha256=4a812857873069094825f4da4ac043677fe4f5e32c5804b2dc8816dcd5f10f30\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fnqcqmty/wheels/41/18/ee/d5dd158441b27965855b1bbae03fa2d8a91fe645c01b419896\n",
            "Successfully built tqdm\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (1.19.5)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (54.2.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvRL4xjFu6H7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "529aba17-79d1-4090-db94-2b510c0bcc7b"
      },
      "source": [
        "%mkdir Xray/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘Xray/’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNuHxHYxvWqA"
      },
      "source": [
        "!mkdir Xray/annotations\n",
        "!mkdir Xray/Annotations\n",
        "!mkdir Xray/Images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atj1sMpLvhwy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcfda1bc-ac07-45b4-c82e-9d5c3603dc43"
      },
      "source": [
        "%cp train/_annotations.coco.json Xray/annotations/instances_Images.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat 'train/_annotations.coco.json': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x52XCQZovmhl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483646ed-d065-498c-9ad5-9213b02803b9"
      },
      "source": [
        "%cp train/*.jpg Xray/Images/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat 'train/*.jpg': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e05YCbtvp21"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append(\"Monk_Object_Detection/4_efficientdet/lib/\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpS1x1JEvsq1"
      },
      "source": [
        "from train_detector import Detector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "267rJfsqvvjn"
      },
      "source": [
        "gtf = Detector();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjFWRaYuvw1_"
      },
      "source": [
        "#directs the model towards file structure\n",
        "root_dir = \"./\";\n",
        "coco_dir = \"Xray\";\n",
        "img_dir = \"./\";\n",
        "set_dir = \"Images\";"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns1zI4N0vzrG",
        "outputId": "584c21c1-852b-48ac-e612-e9b5a1b735e2"
      },
      "source": [
        "#smells like some free compute from Colab, nice\n",
        "gtf.Train_Dataset(root_dir, coco_dir, img_dir, set_dir, batch_size=8, image_size=512, use_gpu=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OfZJWBQv2Mg",
        "outputId": "a8497472-136f-4618-af9f-40913ea21d94"
      },
      "source": [
        "gtf.Model();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrqoL5Unv34I"
      },
      "source": [
        "gtf.Set_Hyperparams(lr=0.0001, val_interval=1, es_min_delta=0.0, es_patience=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "--EbwnZmv6nf",
        "outputId": "5e065e76-ad3a-42dc-95de-733087c420a6"
      },
      "source": [
        "%%time\n",
        "gtf.Train(num_epochs=20, model_output_dir=\"trained/\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 1/20. Iteration: 5/35. Cls loss: 1.10690. Reg loss: 1.03018. Batch loss: 2.13708 Total loss: 2.16577</span><progress style='margin:2px 4px;description_width:initial;' max='35' value='5'></progress> 14% 5/35 [00:09&lt;00:56,  1.89s/it]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-7c4042803c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gtf.Train(num_epochs=20, model_output_dir=\"trained/\");'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Monk_Object_Detection/4_efficientdet/lib/train_detector.py\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(self, num_epochs, model_output_dir)\u001b[0m\n\u001b[1;32m    262\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"local\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m                             \u001b[0mcls_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"local\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"local\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"local\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                             \u001b[0mcls_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"local\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Monk_Object_Detection/4_efficientdet/lib/src/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mregression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mclassification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Monk_Object_Detection/4_efficientdet/lib/src/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_anchors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLMi0bmzv9a8"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append(\"Monk_Object_Detection/4_efficientdet/lib/\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJhptLQgETot"
      },
      "source": [
        "from infer_detector import Infer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUzz-3GtEV26"
      },
      "source": [
        "gtf = Infer();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6raiqh3CEXgd"
      },
      "source": [
        "#our trained model weights are in here in onxx format\n",
        "gtf.Model(model_dir=\"trained/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2NEGKQKEZMc"
      },
      "source": [
        "#extract class list from our annotations\n",
        "import json\n",
        "with open('Xray/train/_annotations.coco.json') as json_file:\n",
        "    data = json.load(json_file)\n",
        "class_list = []\n",
        "for category in data['categories']:\n",
        "  class_list.append(category['name'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71xkJEDeEbPS"
      },
      "source": [
        "%%time\n",
        "test_images = [f for f in os.listdir('Xray/test') if f.endswith('.jpg')]\n",
        "# import random\n",
        "# img_path = \"Xray/test/\" + random.choice(test_images);\n",
        "\n",
        "for img_path in test_images:\n",
        "  img_path = 'Xray/test/' + img_path\n",
        "  duration, scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.2);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn1OSwIdEds6"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(filename='output.jpg') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4RpART-IBSz"
      },
      "source": [
        "#3. Signatrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmzorYwBPJDq"
      },
      "source": [
        "!!curl -L \"https://app.roboflow.com/ds/4q0xWQkGJr?key=fYtlCsl92J\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkxNSS_NPMlD",
        "outputId": "d1e08a92-cc86-44b6-b092-23cfbe34aeeb"
      },
      "source": [
        "!git clone https://github.com/signatrix/efficientdet.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'efficientdet'...\n",
            "remote: Enumerating objects: 144, done.\u001b[K\n",
            "remote: Total 144 (delta 0), reused 0 (delta 0), pack-reused 144\u001b[K\n",
            "Receiving objects: 100% (144/144), 28.03 MiB | 15.73 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g-jdZdjPxqm"
      },
      "source": [
        "!python train.py --lr 1e-5 --batch_size 8 --num_epochs 100 --image_size 416"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}