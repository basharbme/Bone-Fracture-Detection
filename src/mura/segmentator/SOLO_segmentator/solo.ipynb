{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SOLO.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lcVfCSRa-TNk",
        "rMIwiBjL2CBs"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD4Wi-Gp-DpJ",
        "outputId": "22c4fa62-b521-4b45-c6b2-0794134ec89d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc8M-CIk-EiC"
      },
      "source": [
        "import os\n",
        "\n",
        "os.chdir('/content/drive/MyDrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcVfCSRa-TNk"
      },
      "source": [
        "#1. Prepair data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvgiDcna-YIu",
        "outputId": "b5b3ce76-8e10-41b1-afd5-e5b7c59ff6eb"
      },
      "source": [
        "%cd /content/drive/MyDrive/Solo/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Solo/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_JRO3-zCkKc",
        "outputId": "5492495a-cbaa-4e6d-86ce-87e253ccafe5"
      },
      "source": [
        "# Statistic number of image in each set\n",
        "test_set = os.listdir('/content/drive/MyDrive/Solo/data/XRAYBoneDataset/test/JPEGImages')\n",
        "train_set = os.listdir('/content/drive/MyDrive/Solo/data/XRAYBoneDataset/train/JPEGImages')\n",
        "val_set = os.listdir('/content/drive/MyDrive/Solo/data/XRAYBoneDataset/val/JPEGImages')\n",
        "\n",
        "print('Number of images: ')\n",
        "print(f'Train set: {len(train_set)} images')\n",
        "print(f'Validation set: {len(val_set)} images')\n",
        "print(f'Test set: {len(test_set)} images')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images: \n",
            "Train set: 3199 images\n",
            "Validation set: 801 images\n",
            "Test set: 801 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lqlm3w7kFCaS"
      },
      "source": [
        "#2. SOLOv2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcjaWixJDYyp"
      },
      "source": [
        "# Install pretrained weights\n",
        "!wget https://cloudstor.aarnet.edu.au/plus/s/chF3VKQT4RDoEqC/download -O SOLOv2_R50_3x.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o3a6AG0F9tY",
        "outputId": "ef26ced4-021c-4f34-9579-9c175cd2db3b"
      },
      "source": [
        "!git clone https://github.com/aim-uofa/AdelaiDet.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AdelaiDet'...\n",
            "remote: Enumerating objects: 183, done.\u001b[K\n",
            "remote: Counting objects: 100% (183/183), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 1916 (delta 118), reused 164 (delta 111), pack-reused 1733\u001b[K\n",
            "Receiving objects: 100% (1916/1916), 507.64 KiB | 2.21 MiB/s, done.\n",
            "Resolving deltas: 100% (1162/1162), done.\n",
            "Checking out files: 100% (205/205), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rzI3YfCEMJw",
        "outputId": "67c805e2-f886-4b68-a438-c80102ea60d9"
      },
      "source": [
        "%cd /content/drive/MyDrive/Solo/AdelaiDet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Solo/AdelaiDet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muTsX2Z1GVsi"
      },
      "source": [
        "# install dependencies: \n",
        "!pip install pyyaml==5.1\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOnT_qg9O7Y-"
      },
      "source": [
        "# install detectron2: (Colab has CUDA 10.1 + torch 1.8)\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "import torch\n",
        "assert torch.__version__.startswith(\"1.8\")   # need to manually install torch 1.8 if Colab changes its default version\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
        "# exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGp0S0Oqexhm"
      },
      "source": [
        "# Build adet package\n",
        "!python setup.py build develop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fvi3YasYPAqx"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSrWRjPhnmnM"
      },
      "source": [
        "#visualize training data\n",
        "\n",
        "my_dataset_train_metadata = MetadataCatalog.get(\"train_data\")\n",
        "dataset_dicts = DatasetCatalog.get(\"train_data\")\n",
        "\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "for d in random.sample(dataset_dicts, 3):\n",
        "    img = cv2.imread(d['file_name'])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.5)\n",
        "    vis = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(vis.get_image()[:, :, ::-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5r6UyXWm7oM"
      },
      "source": [
        "## Training and evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns4i31JeIS8m",
        "outputId": "ccc68d50-6fd3-4700-84fd-e20e83e13eb1"
      },
      "source": [
        "# We make our own config to custom model for training in our dataset\n",
        "# Our xray dataset has 3600 images for train, 800 images for validation and 800 images for test.\n",
        "# We achieve our best model after running 600 iterations with some notifications: lr = 0.0025 (decay=True), optimizer=SGD, batch_size=8\n",
        "!OMP_NUM_THREADS=1 python tools/train_net.py \\\n",
        "    --config-file configs/SOLOv2/R50_3x.yaml \\\n",
        "    --num-gpus 1 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "Command Line Args: Namespace(config_file='configs/SOLOv2/R50_3x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)\n",
            "\u001b[32m[04/08 08:17:59 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[04/08 08:18:00 detectron2]: \u001b[0mEnvironment info:\n",
            "----------------------  ---------------------------------------------------------------\n",
            "sys.platform            linux\n",
            "Python                  3.7.10 (default, Feb 20 2021, 21:17:23) [GCC 7.5.0]\n",
            "numpy                   1.19.5\n",
            "detectron2              0.4 @/usr/local/lib/python3.7/dist-packages/detectron2\n",
            "Compiler                GCC 7.3\n",
            "CUDA compiler           CUDA 10.1\n",
            "detectron2 arch flags   3.7, 5.0, 5.2, 6.0, 6.1, 7.0, 7.5\n",
            "DETECTRON2_ENV_MODULE   <not set>\n",
            "PyTorch                 1.8.1+cu101 @/usr/local/lib/python3.7/dist-packages/torch\n",
            "PyTorch debug build     False\n",
            "GPU available           True\n",
            "GPU 0                   Tesla T4 (arch=7.5)\n",
            "CUDA_HOME               /usr/local/cuda\n",
            "Pillow                  7.1.2\n",
            "torchvision             0.9.1+cu101 @/usr/local/lib/python3.7/dist-packages/torchvision\n",
            "torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5\n",
            "fvcore                  0.1.3.post20210317\n",
            "cv2                     4.1.2\n",
            "----------------------  ---------------------------------------------------------------\n",
            "PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 10.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
            "  - CuDNN 7.6.3\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.1, CUDNN_VERSION=7.6.3, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
            "\n",
            "\u001b[32m[04/08 08:18:00 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='configs/SOLOv2/R50_3x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)\n",
            "\u001b[32m[04/08 08:18:00 detectron2]: \u001b[0mContents of args.config_file=configs/SOLOv2/R50_3x.yaml:\n",
            "_BASE_: \"Base-SOLOv2.yaml\"\n",
            "MODEL:\n",
            "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"\n",
            "  RESNETS:\n",
            "    DEPTH: 50\n",
            "SOLVER:\n",
            "  STEPS: (210000, 250000)\n",
            "  MAX_ITER: 270000\n",
            "\n",
            "\u001b[32m[04/08 08:18:00 detectron2]: \u001b[0mRunning with full config:\n",
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 4\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('coco_2017_val',)\n",
            "  TRAIN: ('coco_2017_train',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    CROP_INSTANCE: True\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  HFLIP_TRAIN: True\n",
            "  MASK_FORMAT: bitmask\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32, 64, 128, 256, 512]]\n",
            "  BACKBONE:\n",
            "    ANTI_ALIAS: False\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  BASIS_MODULE:\n",
            "    ANN_SET: coco\n",
            "    COMMON_STRIDE: 8\n",
            "    CONVS_DIM: 128\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5']\n",
            "    LOSS_ON: False\n",
            "    LOSS_WEIGHT: 0.3\n",
            "    NAME: ProtoNet\n",
            "    NORM: SyncBN\n",
            "    NUM_BASES: 4\n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 3\n",
            "  BATEXT:\n",
            "    CANONICAL_SIZE: 96\n",
            "    CONV_DIM: 256\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4']\n",
            "    NUM_CHARS: 25\n",
            "    NUM_CONV: 2\n",
            "    POOLER_RESOLUTION: (8, 32)\n",
            "    POOLER_SCALES: (0.25, 0.125, 0.0625)\n",
            "    RECOGNITION_LOSS: ctc\n",
            "    RECOGNIZER: attn\n",
            "    SAMPLING_RATIO: 1\n",
            "    VOC_SIZE: 96\n",
            "  BLENDMASK:\n",
            "    ATTN_SIZE: 14\n",
            "    BOTTOM_RESOLUTION: 56\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "    POOLER_SAMPLING_RATIO: 1\n",
            "    POOLER_SCALES: (0.25,)\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    TOP_INTERP: bilinear\n",
            "    VISUALIZE: False\n",
            "  BOXINST:\n",
            "    BOTTOM_PIXELS_REMOVED: 10\n",
            "    ENABLED: False\n",
            "    PAIRWISE:\n",
            "      COLOR_THRESH: 0.3\n",
            "      DILATION: 2\n",
            "      SIZE: 3\n",
            "      WARMUP_ITERS: 10000\n",
            "  BiFPN:\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    NUM_REPEATS: 6\n",
            "    OUT_CHANNELS: 160\n",
            "  CONDINST:\n",
            "    BOTTOM_PIXELS_REMOVED: -1\n",
            "    MASK_BRANCH:\n",
            "      CHANNELS: 128\n",
            "      IN_FEATURES: ['p3', 'p4', 'p5']\n",
            "      NORM: BN\n",
            "      NUM_CONVS: 4\n",
            "      OUT_CHANNELS: 8\n",
            "      SEMANTIC_LOSS_ON: False\n",
            "    MASK_HEAD:\n",
            "      CHANNELS: 8\n",
            "      DISABLE_REL_COORDS: False\n",
            "      NUM_LAYERS: 3\n",
            "      USE_FP16: False\n",
            "    MASK_OUT_STRIDE: 4\n",
            "    MAX_PROPOSALS: -1\n",
            "    TOPK_PROPOSALS_PER_IM: -1\n",
            "  DEVICE: cuda\n",
            "  DLA:\n",
            "    CONV_BODY: DLA34\n",
            "    NORM: FrozenBN\n",
            "    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']\n",
            "  FCOS:\n",
            "    CENTER_SAMPLE: True\n",
            "    FPN_STRIDES: [8, 16, 32, 64, 128]\n",
            "    INFERENCE_TH_TEST: 0.05\n",
            "    INFERENCE_TH_TRAIN: 0.05\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    LOC_LOSS_TYPE: giou\n",
            "    LOSS_ALPHA: 0.25\n",
            "    LOSS_GAMMA: 2.0\n",
            "    LOSS_NORMALIZER_CLS: fg\n",
            "    LOSS_WEIGHT_CLS: 1.0\n",
            "    NMS_TH: 0.6\n",
            "    NORM: GN\n",
            "    NUM_BOX_CONVS: 4\n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CLS_CONVS: 4\n",
            "    NUM_SHARE_CONVS: 0\n",
            "    POST_NMS_TOPK_TEST: 100\n",
            "    POST_NMS_TOPK_TRAIN: 100\n",
            "    POS_RADIUS: 1.5\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 1000\n",
            "    PRIOR_PROB: 0.01\n",
            "    SIZES_OF_INTEREST: [64, 128, 256, 512]\n",
            "    THRESH_WITH_CTR: False\n",
            "    TOP_LEVELS: 2\n",
            "    USE_DEFORMABLE: False\n",
            "    USE_RELU: True\n",
            "    USE_SCALE: True\n",
            "    YIELD_PROPOSAL: False\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: True\n",
            "  MEInst:\n",
            "    AGNOSTIC: True\n",
            "    CENTER_SAMPLE: True\n",
            "    DIM_MASK: 60\n",
            "    FLAG_PARAMETERS: False\n",
            "    FPN_STRIDES: [8, 16, 32, 64, 128]\n",
            "    GCN_KERNEL_SIZE: 9\n",
            "    INFERENCE_TH_TEST: 0.05\n",
            "    INFERENCE_TH_TRAIN: 0.05\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    LAST_DEFORMABLE: False\n",
            "    LOC_LOSS_TYPE: giou\n",
            "    LOSS_ALPHA: 0.25\n",
            "    LOSS_GAMMA: 2.0\n",
            "    LOSS_ON_MASK: False\n",
            "    MASK_LOSS_TYPE: mse\n",
            "    MASK_ON: True\n",
            "    MASK_SIZE: 28\n",
            "    NMS_TH: 0.6\n",
            "    NORM: GN\n",
            "    NUM_BOX_CONVS: 4\n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CLS_CONVS: 4\n",
            "    NUM_MASK_CONVS: 4\n",
            "    NUM_SHARE_CONVS: 0\n",
            "    PATH_COMPONENTS: datasets/coco/components/coco_2017_train_class_agnosticTrue_whitenTrue_sigmoidTrue_60.npz\n",
            "    POST_NMS_TOPK_TEST: 100\n",
            "    POST_NMS_TOPK_TRAIN: 100\n",
            "    POS_RADIUS: 1.5\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 1000\n",
            "    PRIOR_PROB: 0.01\n",
            "    SIGMOID: True\n",
            "    SIZES_OF_INTEREST: [64, 128, 256, 512]\n",
            "    THRESH_WITH_CTR: False\n",
            "    TOP_LEVELS: 2\n",
            "    TYPE_DEFORMABLE: DCNv1\n",
            "    USE_DEFORMABLE: False\n",
            "    USE_GCN_IN_MASK: False\n",
            "    USE_RELU: True\n",
            "    USE_SCALE: True\n",
            "    WHITEN: True\n",
            "  META_ARCHITECTURE: SOLOv2\n",
            "  MOBILENET: False\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_INTERVAL: 1\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 50\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: \n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 0\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 512\n",
            "    IN_FEATURES: ['res4']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: Res5ROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 80\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['res4']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 2000\n",
            "    PRE_NMS_TOPK_TEST: 6000\n",
            "    PRE_NMS_TOPK_TRAIN: 12000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  SOLOV2:\n",
            "    FPN_INSTANCE_STRIDES: [8, 8, 16, 32, 32]\n",
            "    FPN_SCALE_RANGES: ((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048))\n",
            "    INSTANCE_CHANNELS: 512\n",
            "    INSTANCE_IN_CHANNELS: 256\n",
            "    INSTANCE_IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    LOSS:\n",
            "      DICE_WEIGHT: 3.0\n",
            "      FOCAL_ALPHA: 0.25\n",
            "      FOCAL_GAMMA: 2.0\n",
            "      FOCAL_USE_SIGMOID: True\n",
            "      FOCAL_WEIGHT: 1.0\n",
            "    MASK_CHANNELS: 128\n",
            "    MASK_IN_CHANNELS: 256\n",
            "    MASK_IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    MASK_THR: 0.5\n",
            "    MAX_PER_IMG: 100\n",
            "    NMS_KERNEL: gaussian\n",
            "    NMS_PRE: 500\n",
            "    NMS_SIGMA: 2\n",
            "    NMS_TYPE: matrix\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 80\n",
            "    NUM_GRIDS: [40, 36, 24, 16, 12]\n",
            "    NUM_INSTANCE_CONVS: 4\n",
            "    NUM_KERNELS: 256\n",
            "    NUM_MASKS: 256\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THR: 0.1\n",
            "    SIGMA: 0.2\n",
            "    TYPE_DCN: DCN\n",
            "    UPDATE_THR: 0.05\n",
            "    USE_COORD_CONV: True\n",
            "    USE_DCN_IN_INSTANCE: False\n",
            "  TOP_MODULE:\n",
            "    DIM: 16\n",
            "    NAME: conv\n",
            "  VOVNET:\n",
            "    BACKBONE_OUT_CHANNELS: 256\n",
            "    CONV_BODY: V-39-eSE\n",
            "    NORM: FrozenBN\n",
            "    OUT_CHANNELS: 256\n",
            "    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']\n",
            "  WEIGHTS: detectron2://ImageNetPretrained/MSRA/R-50.pkl\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: False\n",
            "  BASE_LR: 0.01\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 16\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 270000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.01\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: 0.0001\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n",
            "\u001b[32m[04/08 08:18:00 detectron2]: \u001b[0mFull config saved to ./output/config.yaml\n",
            "\u001b[32m[04/08 08:18:00 d2.utils.env]: \u001b[0mUsing a generated random seed 304296\n",
            "\u001b[32m[04/08 08:18:04 d2.engine.defaults]: \u001b[0mModel:\n",
            "SOLOv2(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ins_head): SOLOv2InsHead(\n",
            "    (cate_tower): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (7): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (8): ReLU(inplace=True)\n",
            "      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (10): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (11): ReLU(inplace=True)\n",
            "    )\n",
            "    (kernel_tower): Sequential(\n",
            "      (0): Conv2d(258, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (4): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (7): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (8): ReLU(inplace=True)\n",
            "      (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (10): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
            "      (11): ReLU(inplace=True)\n",
            "    )\n",
            "    (cate_pred): Conv2d(512, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (kernel_pred): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (mask_head): SOLOv2MaskHead(\n",
            "    (convs_all_levels): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (conv0): Sequential(\n",
            "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (conv0): Sequential(\n",
            "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (conv0): Sequential(\n",
            "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "        (conv1): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (conv0): Sequential(\n",
            "          (0): Conv2d(258, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample0): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "        (conv1): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample1): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "        (conv2): Sequential(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (upsample2): Upsample(scale_factor=2.0, mode=bilinear)\n",
            "      )\n",
            "    )\n",
            "    (conv_pred): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[04/08 08:18:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[04/08 08:18:04 adet.data.dataset_mapper]: \u001b[0mRebuilding the augmentations. The previous augmentations will be overridden.\n",
            "\u001b[32m[04/08 08:18:04 adet.data.detection_utils]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/08 08:18:04 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[04/08 08:18:04 d2.data.datasets.coco]: \u001b[0mLoaded 3199 images in COCO format from /content/drive/MyDrive/Solo/AdelaiDet/datasets/xray/annotations/instances_train.json\n",
            "\u001b[32m[04/08 08:18:04 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 3199 images left.\n",
            "\u001b[32m[04/08 08:18:04 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
            "\u001b[36m|   category   | #instances   |  category  | #instances   |\n",
            "|:------------:|:-------------|:----------:|:-------------|\n",
            "| _background_ | 0            |    bone    | 3201         |\n",
            "|              |              |            |              |\n",
            "|    total     | 3201         |            |              |\u001b[0m\n",
            "\u001b[32m[04/08 08:18:04 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[04/08 08:18:04 d2.data.common]: \u001b[0mSerializing 3199 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/08 08:18:04 d2.data.common]: \u001b[0mSerialized dataset takes 4.09 MiB\n",
            "2021-04-08 08:18:04.915819: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[32m[04/08 08:18:06 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from /content/drive/MyDrive/Solo/AdelaiDet/training_dir/SOLOv2_R50_3x/model_final.pth\n",
            "\u001b[32m[04/08 08:18:06 adet.trainer]: \u001b[0mStarting training from iteration 0\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3503: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "\u001b[32m[04/08 08:18:17 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to training_dir/SOLOv2_R50_3x/model_final.pth\n",
            "\u001b[32m[04/08 08:18:18 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 2  total_loss: 0.28  loss_ins: 0.14  loss_cate: 0.1536  time: 3.2822  data_time: 1.0153  lr: 2.995e-06  max_mem: 9832M\n",
            "\u001b[32m[04/08 08:18:18 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:04 (0:00:01 on hooks)\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/08 08:18:19 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[04/08 08:18:19 d2.data.datasets.coco]: \u001b[0mLoaded 801 images in COCO format from /content/drive/MyDrive/Solo/AdelaiDet/datasets/xray/annotations/instances_val.json\n",
            "\u001b[32m[04/08 08:18:19 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
            "\u001b[36m|   category   | #instances   |  category  | #instances   |\n",
            "|:------------:|:-------------|:----------:|:-------------|\n",
            "| _background_ | 0            |    bone    | 801          |\n",
            "|              |              |            |              |\n",
            "|    total     | 801          |            |              |\u001b[0m\n",
            "\u001b[32m[04/08 08:18:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[04/08 08:18:19 d2.data.common]: \u001b[0mSerializing 801 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[04/08 08:18:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.01 MiB\n",
            "\u001b[32m[04/08 08:18:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 801 images\n",
            "\u001b[32m[04/08 08:18:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/801. 0.1117 s / img. ETA=0:01:31\n",
            "\u001b[32m[04/08 08:18:25 d2.evaluation.evaluator]: \u001b[0mInference done 54/801. 0.1118 s / img. ETA=0:01:27\n",
            "\u001b[32m[04/08 08:18:30 d2.evaluation.evaluator]: \u001b[0mInference done 96/801. 0.1127 s / img. ETA=0:01:23\n",
            "\u001b[32m[04/08 08:18:35 d2.evaluation.evaluator]: \u001b[0mInference done 139/801. 0.1129 s / img. ETA=0:01:18\n",
            "\u001b[32m[04/08 08:18:40 d2.evaluation.evaluator]: \u001b[0mInference done 181/801. 0.1136 s / img. ETA=0:01:13\n",
            "\u001b[32m[04/08 08:18:45 d2.evaluation.evaluator]: \u001b[0mInference done 223/801. 0.1142 s / img. ETA=0:01:08\n",
            "\u001b[32m[04/08 08:18:50 d2.evaluation.evaluator]: \u001b[0mInference done 265/801. 0.1145 s / img. ETA=0:01:03\n",
            "\u001b[32m[04/08 08:18:56 d2.evaluation.evaluator]: \u001b[0mInference done 308/801. 0.1144 s / img. ETA=0:00:58\n",
            "\u001b[32m[04/08 08:19:01 d2.evaluation.evaluator]: \u001b[0mInference done 349/801. 0.1150 s / img. ETA=0:00:54\n",
            "\u001b[32m[04/08 08:19:06 d2.evaluation.evaluator]: \u001b[0mInference done 389/801. 0.1156 s / img. ETA=0:00:49\n",
            "\u001b[32m[04/08 08:19:11 d2.evaluation.evaluator]: \u001b[0mInference done 430/801. 0.1160 s / img. ETA=0:00:44\n",
            "\u001b[32m[04/08 08:19:16 d2.evaluation.evaluator]: \u001b[0mInference done 470/801. 0.1165 s / img. ETA=0:00:40\n",
            "\u001b[32m[04/08 08:19:21 d2.evaluation.evaluator]: \u001b[0mInference done 510/801. 0.1170 s / img. ETA=0:00:35\n",
            "\u001b[32m[04/08 08:19:26 d2.evaluation.evaluator]: \u001b[0mInference done 549/801. 0.1175 s / img. ETA=0:00:30\n",
            "\u001b[32m[04/08 08:19:31 d2.evaluation.evaluator]: \u001b[0mInference done 589/801. 0.1177 s / img. ETA=0:00:25\n",
            "\u001b[32m[04/08 08:19:36 d2.evaluation.evaluator]: \u001b[0mInference done 630/801. 0.1179 s / img. ETA=0:00:20\n",
            "\u001b[32m[04/08 08:19:41 d2.evaluation.evaluator]: \u001b[0mInference done 671/801. 0.1180 s / img. ETA=0:00:15\n",
            "\u001b[32m[04/08 08:19:46 d2.evaluation.evaluator]: \u001b[0mInference done 711/801. 0.1182 s / img. ETA=0:00:11\n",
            "\u001b[32m[04/08 08:19:51 d2.evaluation.evaluator]: \u001b[0mInference done 752/801. 0.1182 s / img. ETA=0:00:06\n",
            "\u001b[32m[04/08 08:19:56 d2.evaluation.evaluator]: \u001b[0mInference done 793/801. 0.1182 s / img. ETA=0:00:00\n",
            "\u001b[32m[04/08 08:19:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:37.948168 (0.123050 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/08 08:19:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:34 (0.118178 s / img per device, on 1 devices)\n",
            "\u001b[32m[04/08 08:19:57 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[04/08 08:19:57 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to training_dir/SOLOv2_R50_3x/inference/coco_instances_results.json\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.25 seconds.\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 0.000 | 0.000  | 0.000  |  nan  |  nan  | 0.000 |\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category     | AP   | category   | AP    |\n",
            "|:-------------|:-----|:-----------|:------|\n",
            "| _background_ | nan  | bone       | 0.000 |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.13s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *segm*\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.25 seconds.\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.858\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.989\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.981\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.858\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.888\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.903\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.903\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.903\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
            "| 85.830 | 98.937 | 98.145 |  nan  |  nan  | 85.830 |\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category     | AP   | category   | AP     |\n",
            "|:-------------|:-----|:-----------|:-------|\n",
            "| _background_ | nan  | bone       | 85.830 |\n",
            "\u001b[32m[04/08 08:19:58 d2.engine.defaults]: \u001b[0mEvaluation results for val_data in csv format:\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.testing]: \u001b[0mcopypaste: 0.0000,0.0000,0.0000,nan,nan,0.0000\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[04/08 08:19:58 d2.evaluation.testing]: \u001b[0mcopypaste: 85.8296,98.9370,98.1446,nan,nan,85.8296\n",
            "\u001b[32m[04/08 08:19:58 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 2  total_loss: 0.28  loss_ins: 0.14  loss_cate: 0.1536  time: 3.2822  data_time: 1.0153  lr: 2.995e-06  max_mem: 9832M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmqtVXuBm24S"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huzkC0BmxAEV",
        "outputId": "64caec43-a5b0-4265-a1e8-85d945781d57"
      },
      "source": [
        "\n",
        "!python demo/demo.py \\\n",
        "    --config-file configs/SOLOv2/R50_3x.yaml \\\n",
        "    --input /content/drive/MyDrive/Solo/AdelaiDet/datasets/xray/test/JPEGImages/patient09379_study1_negative_image1.jpg \\\n",
        "    --output output.jpg \\\n",
        "    --opts MODEL.WEIGHTS /content/drive/MyDrive/Solo/AdelaiDet/training_dir/SOLOv2_R50_3x/model_final.pth"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[04/08 08:44:40 detectron2]: \u001b[0mArguments: Namespace(confidence_threshold=0.3, config_file='configs/SOLOv2/R50_3x.yaml', input=['/content/drive/MyDrive/Solo/AdelaiDet/datasets/xray/test/JPEGImages/patient09379_study1_negative_image1.jpg'], opts=['MODEL.WEIGHTS', '/content/drive/MyDrive/Solo/AdelaiDet/training_dir/SOLOv2_R50_3x/model_final.pth'], output='output.jpg', video_input=None, webcam=False)\n",
            "  0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3503: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  \"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "\u001b[32m[04/08 08:44:45 detectron2]: \u001b[0m/content/drive/MyDrive/Solo/AdelaiDet/datasets/xray/test/JPEGImages/patient09379_study1_negative_image1.jpg: detected 3 instances in 0.23s\n",
            "100% 1/1 [00:00<00:00,  3.53it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMIwiBjL2CBs"
      },
      "source": [
        "#3. SOLOv1 (Not complete because this code compatible in conda environment)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ekv5LTaY2D6l",
        "outputId": "9430d9b4-9a7b-44cc-c687-be8389bc6b41"
      },
      "source": [
        "!git clone https://github.com/WXinlong/SOLO.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SOLO'...\n",
            "remote: Enumerating objects: 6428, done.\u001b[K\n",
            "remote: Total 6428 (delta 0), reused 0 (delta 0), pack-reused 6428\u001b[K\n",
            "Receiving objects: 100% (6428/6428), 6.05 MiB | 6.97 MiB/s, done.\n",
            "Resolving deltas: 100% (4417/4417), done.\n",
            "Checking out files: 100% (457/457), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8TrNhEn5ggW",
        "outputId": "e805c01c-dea4-4f2d-c62a-2c0ed7120f15"
      },
      "source": [
        "cd SOLO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/SOLO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18G2MHJV50BA",
        "outputId": "4fd64858-10aa-4ba5-8ce0-63856c0ca7a1"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mconfigs\u001b[0m/  \u001b[01;34mdocs\u001b[0m/           \u001b[01;34mmmdet\u001b[0m/      \u001b[01;34mrequirements\u001b[0m/     \u001b[01;34mtests\u001b[0m/\n",
            "\u001b[01;34mdemo\u001b[0m/     highlights.png  pytest.ini  requirements.txt  \u001b[01;34mtools\u001b[0m/\n",
            "\u001b[01;34mdocker\u001b[0m/   LICENSE         README.md   setup.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_X4xYQR51oR"
      },
      "source": [
        "!pip install -r requirements/build.txt\n",
        "!pip install \"git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\"\n",
        "!pip install -v -e .  # or \"python setup.py develop\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfbuQG67ZeOX",
        "outputId": "5aff488c-7f44-4514-a6f0-16e05b270518"
      },
      "source": [
        "# Install mmcv\n",
        "\n",
        "!pip uninstall mmcv mmcv-full\n",
        "# !git clone https://github.com/open-mmlab/mmcv.git\n",
        "%cd ./../mmcv\n",
        "!MMCV_WITH_OPS=1 pip install -e ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling mmcv-0.2.16:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/mmcv-0.2.16.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/mmcv/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled mmcv-0.2.16\n",
            "Can't uninstall 'mmcv-full'. No files were found to uninstall.\n",
            "/content/drive/My Drive/mmcv\n",
            "Obtaining file:///content/drive/My%20Drive/mmcv\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.3.0) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.3.0) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.3.0) (6.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.3.0) (3.13)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.3.0) (0.31.0)\n",
            "Installing collected packages: mmcv-full\n",
            "  Found existing installation: mmcv-full 1.3.0\n",
            "    Can't uninstall 'mmcv-full'. No files were found to uninstall.\n",
            "  Running setup.py develop for mmcv-full\n",
            "Successfully installed mmcv-full\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMMFES-JgDnY",
        "outputId": "41c4e868-951a-4ad3-c556-72d8d7aff47f"
      },
      "source": [
        "%cd /content/drive/MyDrive/SOLO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/SOLO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKEnONlhYYEk"
      },
      "source": [
        "!export COCO_ROOT=/content/drive/MyDrive/SOLO/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fvq4IYQZY0cX",
        "outputId": "566d3bb6-1416-4722-8a10-37cb83a63747"
      },
      "source": [
        "!python tools/train.py configs/solo/solo_r50_fpn_8gpu_1x.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-07 10:57:43,898 - mmdet - INFO - Distributed training: False\n",
            "2021-04-07 10:57:43,899 - mmdet - INFO - MMDetection Version: 2.11.0\n",
            "2021-04-07 10:57:43,900 - mmdet - INFO - Config:\n",
            "/content/drive/My Drive/SOLO/configs/solo/solo_r50_fpn_8gpu_1x.py\n",
            "# model settings\n",
            "model = dict(\n",
            "    type='SOLO',\n",
            "    pretrained='torchvision://resnet50',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        depth=50,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3), # C2, C3, C4, C5\n",
            "        frozen_stages=1,\n",
            "        style='pytorch'),\n",
            "    neck=dict(\n",
            "        type='FPN',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        start_level=0,\n",
            "        num_outs=5),\n",
            "    bbox_head=dict(\n",
            "        type='SOLOHead',\n",
            "        num_classes=2,\n",
            "        in_channels=256,\n",
            "        stacked_convs=7,\n",
            "        seg_feat_channels=256,\n",
            "        strides=[8, 8, 16, 32, 32],\n",
            "        scale_ranges=((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048)),\n",
            "        sigma=0.2,\n",
            "        num_grids=[40, 36, 24, 16, 12],\n",
            "        cate_down_pos=0,\n",
            "        with_deform=False,\n",
            "        loss_ins=dict(\n",
            "            type='DiceLoss',\n",
            "            use_sigmoid=True,\n",
            "            loss_weight=3.0),\n",
            "        loss_cate=dict(\n",
            "            type='FocalLoss',\n",
            "            use_sigmoid=True,\n",
            "            gamma=2.0,\n",
            "            alpha=0.25,\n",
            "            loss_weight=1.0),\n",
            "    ))\n",
            "# training and testing settings\n",
            "train_cfg = dict()\n",
            "test_cfg = dict(\n",
            "    nms_pre=500,\n",
            "    score_thr=0.1,\n",
            "    mask_thr=0.5,\n",
            "    update_thr=0.05,\n",
            "    kernel='gaussian',  # gaussian/linear\n",
            "    sigma=2.0,\n",
            "    max_per_img=100)\n",
            "# dataset settings\n",
            "dataset_type = 'CocoDataset'\n",
            "data_root = 'data/coco/'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
            "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
            "    dict(type='RandomFlip', flip_ratio=0.5),\n",
            "    dict(type='Normalize', **img_norm_cfg),\n",
            "    dict(type='Pad', size_divisor=32),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(1333, 800),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='Resize', keep_ratio=True),\n",
            "            dict(type='RandomFlip'),\n",
            "            dict(type='Normalize', **img_norm_cfg),\n",
            "            dict(type='Pad', size_divisor=32),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img']),\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    imgs_per_gpu=2,\n",
            "    workers_per_gpu=2,\n",
            "    train=dict(\n",
            "        type=dataset_type,\n",
            "        ann_file=data_root + 'annotations/instances_train2017.json',\n",
            "        img_prefix=data_root + 'train2017/',\n",
            "        pipeline=train_pipeline),\n",
            "    val=dict(\n",
            "        type=dataset_type,\n",
            "        ann_file=data_root + 'annotations/instances_val2017.json',\n",
            "        img_prefix=data_root + 'val2017/',\n",
            "        pipeline=test_pipeline),\n",
            "    test=dict(\n",
            "        type=dataset_type,\n",
            "        ann_file=data_root + 'annotations/instances_val2017.json',\n",
            "        img_prefix=data_root + 'val2017/',\n",
            "        pipeline=test_pipeline))\n",
            "# optimizer\n",
            "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
            "# learning policy\n",
            "lr_config = dict(\n",
            "    policy='step',\n",
            "    warmup='linear',\n",
            "    warmup_iters=500,\n",
            "    warmup_ratio=1.0 / 3,\n",
            "    step=[9, 11])\n",
            "checkpoint_config = dict(interval=1)\n",
            "# yapf:disable\n",
            "log_config = dict(\n",
            "    interval=50,\n",
            "    hooks=[\n",
            "        dict(type='TextLoggerHook'),\n",
            "        # dict(type='TensorboardLoggerHook')\n",
            "    ])\n",
            "# yapf:enable\n",
            "# runtime settings\n",
            "total_epochs = 12\n",
            "device_ids = range(8)\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "work_dir = './work_dirs/solo_release_r50_fpn_8gpu_1x'\n",
            "load_from = None\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/mmdet/models/builder.py:72: UserWarning: train_cfg and test_cfg is deprecated, please specify them in model\n",
            "  'please specify them in model', UserWarning)\n",
            "Traceback (most recent call last):\n",
            "  File \"tools/train.py\", line 125, in <module>\n",
            "    main()\n",
            "  File \"tools/train.py\", line 101, in main\n",
            "    cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmdet/models/builder.py\", line 77, in build_detector\n",
            "    return build(cfg, DETECTORS, dict(train_cfg=train_cfg, test_cfg=test_cfg))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/mmdet/models/builder.py\", line 34, in build\n",
            "    return build_from_cfg(cfg, registry, default_args)\n",
            "  File \"/content/drive/My Drive/mmcv/mmcv/utils/registry.py\", line 172, in build_from_cfg\n",
            "    f'{obj_type} is not in the {registry.name} registry')\n",
            "KeyError: 'SOLO is not in the detector registry'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s0EXgnfSQ3J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}